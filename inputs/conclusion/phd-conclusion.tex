\documentclass[PhD-Yoann-Dupont.tex]{subfiles}
\begin{document}

Cette thèse a porté sur le domaine général du TAL, et plus particulièrement sur la tâche de reconnaissance des entités nommées. Nous avons vu que les entités nommées n'étaient pas des objets théoriques aussi clairement définis que peuvent l'être les constituants/dépendances syntaxiques, les anaphores et coréférents. Nous avons vu que la notion d'entité nommée s'est principalement construite de manière très concrète et appliquée, construites principalement autour de défis qui proposent des définitions plus ou moins larges et complexes dans un but applicatif concret. Nous avons donc commencé par présenter les différents corpus d'entités nommées nous intéressant plus particulièrement dans le cadre de cette thèse. Nous avons également exploré les différentes méthodes utilisées pour répondre à cette tâche. Ces méthodes incluent deux grandes catégories : les méthodes à base de règles et celles par apprentissage automatique. Nous avons vu que les méthodes par apprentissage automatique étaient plus adaptées à la tâche en raison de leur meilleure adaptabilité, leur permettant de mieux répondre à la tâche et d'obtenir une meilleure qualité de manière quasi-systématique.

Dans le cadre de cette thèse, nous avons abordé la structuration dans les entités nommées. Nous avons vu que cette structuration pouvait avoir plusieurs aspects. Tout d'abord, une entité peut avoir une structuration morphologique, cela est notamment le cas pour les entités nommées biomédicales et tout particulièrement pour les entités nommées chimiques, où des \emph{affixes caractéristiques} peuvent être trouvés par fouille de sous-chaînes répétées et être utilisées dans des méthodes de reconnaissance d'entités nommées. Notre contribution ici a été de fournir un algorithme générique de fouille de sous-chaînes répétées et leur intégration dans un algorithme par apprentissage. Ces travaux ont été publiés dans \citet{dupont2016extraction}. Nous avons également vu que cette structuration morphologique pouvait s'étendre presque à l'identique à une structuration syntagmatique, où certains tokens récurrents, appelés \emph{tokens déclencheurs}, servent à marquer la présence d'une entité nommée. Nous avons alors étudié les entités nommées structurées, où les entités n'ont plus une structure linéaire, mais arborée. Nous avons développé pour chaque type de structuration des approches spécifiques afin de répondre au problème. Nous avons également comparé deux technologies, les CRF et les réseaux de neurones, afin de répondre à chacune des tâches que nous avons abordées.

Pour les structurations morphologique et syntagmatique, nous avons concu une méthode afin d'extraire les éléments pertinents en se basant sur l'algorithme de la plus longue sous-chaîne commune. Cet algorithme permettait d'extraire des éléments constitutifs importants d'une entité nommée. Ces éléments constitutifs pouvaient se retrouver à deux échelles selon le domaine d'application. Ils pouvaient être récupérés à l'échelle du token lorsque la structuration souhaitée est de nature morphologique et à l'échelle de la séquence de tokens d'une entité nommée si la structuration voulue est syntagmatique. Ces méthodes d'extraction automatique ont été conçues afin d'alimenter des systèmes à base d'apprentissage, en leur fournissant des informations en entrée capables de les aider à mieux identifier les entités cibles. Nous avons montré les apports positifs de notre approche dans les deux cas. Ces travaux m'ont permis d'obtenir un système état-de-l'art sur le FTB annoté en entités nommées ainsi que le prix du meilleur article RECITAL à la conférence TALN-RECITAL 2017 \citep{dupont2017exploration}.

Nous avons également abordé les entités nommées structurées. Nous avons vu que la tâche demeure plutôt récente, les solutions proposées sur ce type d'entités nommées s'inspirent généralement de méthodes classiques (parsing, cascades de modèles linéaires, etc.) et demeurent assez peu nombreuses. Les cascades de modèles sont les approches ayant remporté les campagnes ETAPE et Quaero \citep{dinarelli2012,raymond2013robust}. Plus particulièrement, une cascade de CRF avait déjà été proposée par \citet{raymond2013robust}. Une limitation des approches à base de cascade de modèles linéaires venait de leur profondeur fixe. \citet{Tsuruoka09} a offert une proposition pour l'analyse syntaxique, cette dernière ne pouvant se transposer à des arbres d'entités nommées, "creux" par nature. Notre contribution en ce point a été de formaliser les approches par cascades de CRF pour les entités nommées et de les étendre afin qu'une profondeur arbitraire puisse être atteinte. Ces travaux m'ont permis de publier dans \citet{dupont2017b}.

Depuis quelques années, une certaine concurrence s'est établie entre les réseaux de neurones et les CRF. Nous avons voulu comparer dans cette thèse les deux approches de manière la plus juste possible. Bien que chaque méthode ait ses avantages et ses inconvénients, nous avons remarqué de manière quasi-systématique que les réseaux de neurones avaient une meilleure qualité sur les entités inconnues que les CRF. Cela suppose que les réseaux de neurones ont une meilleure capacité de généralisation que les CRF, un résultat également suggéré dans l'étude faite par \citet{augenstein2017generalisation}. Nous prévoyons d'étudier plus en détail le pourquoi de cette meilleure généralisation dans des recherches futures. Nous savons déjà que le calcul de représentations distributionnelles des tokens (et, de plus en plus, des étiquettes) offre aux réseaux de neurones une meilleure capacité à prendre en compte le contexte. Les CRF n'ont pas cette capacité car ils utilisent une représentation creuse, l'ensemble des traits qu'ils observent sont supposés indépendants, mais ils ont une meilleure capacité à accepter des traits plus nombreux et complexes qu'il serait laborieux (et pas nécessairement utile) d'intégrer dans un réseau de neurones. Un écart se dessine plus nettement lorsque les réseaux de neurones disposent de représentations pré-apprises, qui leur permet d'observer un nombre conséquent de tokens différents et de capturer des informations fines. Les différences de résultats observées en utilisant ce type de représentation montrent cependant plus la puissance de ces dernières que du réseau qui les utilise. Comme nous pouvons le voir dans le tableau \ref{tab:CRF-vs-LSTM-vs-SEM} (lignes 3, 5 et 7) qu'un CRF enrichi de lexique a une meilleure qualité qu'un NN enrichi de la même façon, mais que l'utilisation de représentations pré-apprises permet au NN de dépasser le CRF en termes de qualité. Cette meilleure généralisation offerte par les réseaux de neurones enrichis de représentations précalculées doit cependant être tempérée par divers facteurs. Le facteur le plus important est celui du temps. En effet, les CRF demeurent bien plus rapides à entrainer que les réseaux de neurones, les CRF étant des modèles bien plus simples en comparaison. À cette lenteur à l'apprentissage s'ajoute également une lenteur à l'annotation, où les réseaux de neurones sont bien plus lents que les CRF. Dans des cadres où de très larges volumes de données doivent être traités le plus rapidement possible, ces contraintes doivent être considérées avec un même poids que la qualité pure des modèles.

Les notions de structuration dans les entités nommées offrent encore aujourd'hui de nombreux défis et demeurent un domaine très ouvert. Le premier d'entre eux étant la délimitation de la notion d'une entité nommée. En effet, chaque défi sur les entités nommées apporte une définition particulière des entités nommées. Ces objets linguistiques ayant un caractère très applicatif, il n'est pas rare que leur définition soit souvent inadaptée lorsque le domaine applicatif change. De ce premier problème découle presque naturellement le second : la disponibilité des corpus adaptés. En raison des domaines applicatifs ne correspondant pas totalement aux annotations, il faudrait idéalement recréer de nouvelles annotations, un processus lent et très coûteux. Bien que la plupart des corpus d'entités nommées soient gratuits pour un usage académique, cela n'est pas forcément le cas\footnote{Par exemple, les corpus CHIL \citep{mostefa2007chil} et ETAPE \citep{gravier2012etape} sont payants même pour un usage académique}. Au-delà même de la disponibilité d'un corpus adapté à une application particulière, la qualité du corpus annoté est capitale. Bien que des mesures comme l'accord inter-annotateur existent pour réduire les risques d'annotations incohérentes, obtenir cette mesure n'est pas toujours évident. Parmi les corpus ne disposant pas d'accord inter-annotateur, on peut citer le corpus GENIA \citep{kim2003genia} pour le domaine biomédical, le French Treebank \citep{sagot2012annotation} le CoNLL 2003 \citep{tjong2003introduction}.

Dans cette thèse, nous avons vu une forme de structuration des entités nommées. La vision que nous avons pu en avoir ne couvre cependant pas tous les formes de structuration qu'il est possible de recontrer. Il existe par exemple des cas comme «\ monsieur et madame Macron\ », pour lesquels l'on souhaiterait extraire deux entités différentes. Si l'on tient compte des titres de civilité, la mention «\ monsieur Macron\ » n'est pas contigüe et ne peut pas être capturée par des méthodes linéaires pour extraire deux mentions. Cependant, ces deux entités peuvent être capturées très simplement si les différents éléments sont reliés entre eux comme des dépendances syntaxiques. Ainsi, nous aurions «\ monsieur\ » relié à «\ Macron\ » par le lien "titre", de même pour «\ madame\ ».

Une autre forme de structuration de l'information pour les entités nommées est dans la résolution de chaînes de co-références. Par exemple, Emmanuel Macron peut être référé dans un document par "le président Français" ou par différents pronoms, qu'il est possible de relier à l'entité Emmanuel Macron dans le contexte du document. La résolution de chaînes de co-références permet d'avoir des informations particulièrement utiles sans lesquelles il n'est pas forcément possible de résoudre le problème. En effet la plupart du temps, une entité nommées sera mentionnée via un pronom, de nombreuses relations ne peuvent être extraites qu'en sachant que ce pronom réfère bien à une entité nommée et laquelle.

Atteindre un consensus sur ce que représente une entité nommée parait aujourd'hui encore assez difficile. Dans le Quaero, par exemple, «\ monsieur et madame Macron\ » serait considéré comme un "groupe de personne". Plusieurs interprétations concurrentes sur ce que représente une entité nommée existent aujourd'hui. Nous pouvons cependant explorer certaines pistes :
\begin{itemize}
    \item les entités reliées par un lien logique (et, ou, exclusion, "de ... à", "entre ... et");
    \item le nombre (singulier/pluriel) des entités;
    \item la métonymie;
    \item la co-référence.
\end{itemize}

Des travaux de normalisation des entités nommées ont cependant déjà été réalisés, parmi lesquels Quaero \citet{sekine2002extended,galibert2011structured}. Une première idée serait de comparer les deux jeux d'entités nommées afin de voir dans quelle mesure les deux peuvent être rapprochés afin d'offrir un large panel d'entités nommées qu'il serait possible d'extraire. Un inconvénient des types définis par \citet{sekine2002extended,galibert2011structured} est que la frontière d'entité nommée en devient plus floue. En effet, dans ces définitions étendues, de nombreux noms communs peuvent être considérés comme des entités nommées. Se pose alors la question de quelle est la frontière, \citet{sekine2002extended} admet avoir du prendre des choix arbitraires.

Une perspectives aux travaux effectués au cours de cette thèse est la reconnaissance de relations entre entités nommées. Des premiers travaux encore préliminaires ont été effectués en ce sens, mais ils doivent être appronfondis afin d'obtenir des résultats probants. Le temps que nous avons pu dédier à cette tâche était restreint et le domaine récent. Nous prévoyons de poursuivre nos recherches dans ce domaine, l'extraction de relations étant la tâche succédant naturellement à la reconnaissance des entités nommées.

Outre donc la disponibilité des corpus, il est important de considérer que les entités nommées dépendent souvent de leur corpus et de leur modèle applicatif \citep{ehrmann2008entites}. En suit donc naturellement qu'il est capital de disposer d'outils afin de permettre l'annotation de nouvelles données textuelles afin de mieux répondre aux besoins applicatifs auxquels sont soumis les entités nommées. Des méthodes existent afin d'améliorer à la fois la vitesse d'annotation et l'accord inter-annotateur, ces méthodes sont la principale perspective de ce travail.

\end{document}