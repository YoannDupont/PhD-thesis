\documentclass[PhD-Yoann-Dupont.tex]{subfiles}
\begin{document}


%As a first step we have built a repository of facts that conforms to KBP model. Our first attempt to build such a repository relied on FreeBase (Bollacker et al., 2008) however too many types of relation were missing. The facts are now extracted from Wikidata (Vrandecic and Krotzsch, 2014) : we have queried Wikidata to get the most complete set of Wikidata types (and subtypes) which maps to KBP types and relation types. We then parsed a dump of Wikidata and checked every relation between two entities to test if it is conform to a KBP model. If this is the case, we insert the entities (if they do not already exist) and the relation in the KBP repository. As a second step we build a corpus of sentences which express KBP relations. We used the source texts of TAC-KBP 2014 (news, blog, forum) corpus (Surdeanu and Ji, 2014) to automatically produce a corpus annotated with relations. We used our NER system to detect entities mentions and sentences boundaries. As soon as two entities mentioned in the same sentence are in relation in the repository of facts, we select the sentence and add it to the corpus with an annotation which reflects the fact(s) in the repository.
Pour constituer notre corpus d'apprentissage, nous avons d'abord récupéré un ensemble de faits correspondant au modèle KBP. Notre premier essai s'est basé sur Freebase \citep{bollacker2008freebase}, cependant trop de faits étaient manquants par rapport au modèle KBP présenté dans le tableau \ref{tab:CSSF-relations}. Nous avons donc changé de base de connaissances et avons choisi Wikidata \citep{vrandevcic2014wikidata}, que nous avons requêté afin d'obtenir l'ensemble le plus complet de types et sous-types correspondant au modèle KBP. Nous avons pour cela analysé un dump de Wikidata et avons vérifié l'ensemble des relations entre deux entités afin de voir si cette relation était conforme au modèle KBP. Si tel était le cas, nous avons ajouté les entités et la relation à notre propre base de faits. Nous avons ensuite construit le corpus de phrases exprimant une relation. Nous avons utilisé les textes source du corpus TAC-KBP 2017 (actualité, blog, forum) \citep{surdeanu2014overview} comme données d'entrée pour produire un corpus annoté en relations. Nous avons utilisé les logiciels Luxid afin d'effectuer la segmentation, l'analyse morphosyntaxique et la reconnaissance d'entités nommées. Dès que nous trouvions deux mentions d'entités nommées dans la même phrase et qu'une relation les liait dans notre base, nous avons ajouté la phrase dans notre corpus avec les annotations correspondantes.

Par manque de temps, nous n'avons pas pu effectuer une revue du corpus créé. Lorsque nous l'avons effectuée, après le défi TAC-KBP, il s'est avéré que les phrases d'exemples que nous avions construites étaient du bruit dans la majorité des cas.

%In run\#1, we use facts from FreeBase to produce a first model for 8 relations. In run\#2, we use facts from Wikidata to produce a second model for 25 relations. We notice that about nine tenth of sentences did not express the relation. In spite of this high level of noise, we decided no to filter or enhanced the repository of facts as done in Xu et al. (2013).

\end{document}